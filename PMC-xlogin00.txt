Architektury Výpočetních Systémů (AVS 2023)
Projekt č. 2 (PMC)
Login: xlogin00

Úloha 1: Paralelizace původního řešení
===============================================================================

1) Kterou ze smyček (viz zadání) je vhodnější paralelizovat a co způsobuje 
   neefektivitu paralelizaci té druhé?

   Pridane pragmy:
      baseline (bez pragmy, ziadna paralelizacia) - 762.28 ms (priemer zo 100 behov)

      marchCubes - 380.44 ms (priemer zo 100 behov)
         #pragma omp parallel for reduction(+:totalTriangles) schedule(dynamic, 16)

      evaluateFieldAt - 21684 ms (priemer zo 100 behov)
         #pragma omp parallel for reduction(min: value) linear(pPoints) simdlen(16)

   Vhodnejsie je paralelizovat najvrchnejsiu smycku for vo funkcii marchCubes. Zhorsenie
   casu pri paralelizacii smycky vo funkcii evaluateFieldAt je sposobene velkou reziou
   vytvarania noveho vlakna pre kazdy vrchol pocitanych marching cubes. Pre kazdu
   cube sa vytvori 8 vlakien, a ich paralelizovany urcyhleny vypocet je v porovnani
   s pridanou reziou zanedbatelny.

2) Jaké plánování (rozdělení práce mezi vlákna) jste zvolili a proč? 
   Jaký vliv má velikost "chunk" při dynamickém plánování (8, 16, 32, 64)?

   čím je chunk_size větší, tím je menší
synchronizační režie ale hrubší vyvážení zátěže.
vhodné, když je práce v iteracích stejná (bez chunk_size) nebo se
mění lineárně (pak je chunk_size nutný). 

   static
      8   - 332.32 ms
      16  - 324.70 ms
      32  - 340.96 ms
      64  - 335.64 ms
      128 - 349.98 ms
      
   guided
      8   - 399.42 ms
      16  - 376.14 ms
      32  - 379.54 ms
      64  - 368.76 ms
      128 - 407.42 ms

   dynamic
      8   - 381.10 ms
      16  - 334.82 ms
      32  - 392.78 ms
      64  - 365.28 ms
      128 - 393.52 ms

   Zvolil som static scheduling, kedze mu konzistentne vychadzali najlepsie
   spomedzi vsetkych scheduling typov. V kazdej iteracii sa vykonava vypocet
   pre jednu marching cube, v ktorej sa iteruje cez vsetky vrcholy
   a cez vsetky points v poli. To znamena, ze vypocet je pomerne vyrovnany vo
   vsetkych iteraciach paralelizovanej for smycky a teda je vhodne pouzitie
   schedule(static), pretoze ponuka nizsi overhead v porovnani s dynamickym
   a riadenym rozdelovanim iteracii medzi vlakna v pripade schedule(dynamic)
   a schedule(guided).

   Chunk pri dynamickom dynamickom planovani urcuje velkost casti, na ktore sa
   v runtime rozdeli celkovy pocet iteracii v smycke. Tento typ schedulingu je
   vhodny v pripadoch, kedy sa velkosti (casy) jednotlivych iteracii mozu 
   vyrazne lisit a je vhodne distribuovat "baliky" iteracii az pocas runtime
   nevytazenym vlaknam. 

3) Jakým způsobem zajišťujete ukládání trojúhelníků z několika vláken současně?

   Kedze je metoda `LoopMeshBuilder::emitTriangle` volana sucasne z niekolkych
   vlakien, musime zaistit vzajomne vylucenie tychto operacii. Avsak kvoli
   operacii, ktoru chceme v kritickej sekcii z kazdeho vlakna vykonat
   (std::vector::push_back), nevieme zaistit vzajomne vylucenie pomocou atomic.
   Preto som pouzil `#pragma omp critical`, ktora zaistuje, ze v sekcii kde sa
   pridavaju nove prvky do vektoru mTriangles moze byt vzdy iba jedno vlakno.

Úloha 2: Paralelní průchod stromem
===============================================================================

1) Stručně popište použití OpenMP tasků ve vašem řešení.
V implementacii Octree je rekurzivne zanorenie sa o uroven nizsie paralelizovatelna
cast ulohy a teda je vhodne vyuzitie `task` a `taskwait` konstruktov. Po zavolani
funkcie `TreeMeshBuilder::marchCubes` sa inicializuju hodnoty celkoveho poctu
vytvorenych trojuholnikov a pociatocna suradnica v prvom oktante(0.f, 0.f, 0.f).
Tu sa vytvori paralelna cast a master thread ako prvy zavola rekurzivnu metodu
`TreeMeshBuilder::marchCubesRecursive` (bolo by mozne aj vyuzitie #pragma omp single).
Najprv sa pre aktualnu dekomponovanu cast oktaloveho podstromu skontroluje trivialna
podmienka na vzdialenost k najblizsiemu bodu v priestore `field`. Ak je uz aktualny
podstrom prazdny (navratova funkcia evaluateFieldAt), dalej sa nedekomponuje
a pokracuje sa ku generovaniu polygonov v najmensich marching cubes. Inak sa vytvori
novy OpenMP task a prve volne vlakno ho zacne nezavisle vykonavat a dalej
sa rekurzivne zanori.

Dovetky `task` pragmy osetruju:
- zdielanie atomicky aktualizovanej premennej `totalTriangles` (pomocou `default(shared)`)
- alokaciu privatnej premennej `total_traing_thread` pre navratovu hodnotu rekurzivnej funkcie
- alokaciu a inicializaciu privatnych premennych `i`, `field`
   - inicializacia `field` v tomto pripade nie je problem, kedze ide iba o ukazatel.

Na zaver sa po vygenerovani vsetkych polygonov v danom podstrome atomicky aktualizuje
hodnota totalTriangle (pocet vygenerovanych polygonov v podstrome). Na konci metody
`TreeMeshBuilder::marchCubesRecursive` este musi vlakno pockat na dokoncenie
vsetkych nim vytvorenych taskov, inak by navratova hodnota `totalTriangles` nemusela
byt korektna.

2) Jaký vliv má na vaše řešení tzv. "cut-off"? Je vhodné vytvářet nový 
   task pro každou krychli na nejnižší úrovni?

a) Polygony by mali byt generovane pre kazdu relevantnu marching cube s hranou a<=1
aby odpovedal referencnemu rieseniu, v ktorom je prave a=1. Pri zvoleni vyssej cuf-off 
hodnoty, by vysledny isosurface nebol suvisly ale tvoril by iba "riedky" obrys
objektu z nedostatocneho poctu polygonov.

b) Optimalnejsie riesenie oproti vytvaraniu noveho tasku pre kazdu kocku na najnizsej urovni
je volanie metody buildCube ak uz vieme, za dalsie zanorenie by bolo pod zvolenou cut-off hodnotou.
Tymto pristupom usetrime az mGridSize^3 generovani taskov, kedze pre kazdu najmensiu marching
cube sa zavola metoda `buildCube` este pred zanorenim.

3) Jakým způsobem zajišťujete ukládání trojúhelníků z několika vláken současně?
Tak ako v casti loop mesh builder, bola aj tu vyuzita `#pragma omp critical` zaistujuca,
ze iba jedno vlakno bude v jednom momente ukladat vygenerovane trojuholniky.

Úloha 3: Grafy škálování všech řešení
===============================================================================

1) Stručně zhodnoťte efektivitu vytvořených řešení (na základě grafů ŠKÁLOVÁNÍ).






2) V jakém případě (v závislosti na počtu bodů ve vstupním souboru a velikosti 
   mřížky) bude vaše řešení 1. úlohy neefektivní? (pokud takový případ existuje)

3) Je (nebo není) stromový algoritmus efektivnější z pohledu slabého škálování 
   vzhledem ke vstupu?

4) Jaký je rozdíl mezi silným a slabým škálováním?
a) strong scaling
Pri silnom skalovani vychadzame z predpokladu ze s mnozstvo prace je konstantne a v idealnom
pripade by sa s navysenim vypoctovej sily na dvojnasobok mal cas znizit vypoctu na polovicu.
Avsak vzdy existuje sekvencna (neparalelizovatelna cast)

b) weak scaling

Úloha 4: Analýza využití jader pomocí VTune
================================================================================

1) Jaké bylo průměrné využití jader pro všechny tři implementace s omezením na 
   18 vláken? Na kolik procent byly využity?
   
   ref:
   loop:
   tree:

2) Jaké bylo průměrné využití jader pro všechny tři implementace s využitím 
   všech jader? Na kolik procent se podařilo využít obě CPU?
   
   ref:
   loop:
   tree:

3) Jaké jsou závěry z těchto měření?
